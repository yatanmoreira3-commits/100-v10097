#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Auto Save Manager
Sistema de salvamento autom√°tico e imediato de todos os resultados
"""

import os
import json
import time
import logging
import random
import string
import re
from datetime import datetime
from typing import Dict, Any, Optional, List
import uuid
from pathlib import Path
import shutil
from datetime import timedelta
import gzip
import traceback

logger = logging.getLogger(__name__)

class AutoSaveManager:
    """Gerenciador de salvamento autom√°tico ultra-robusto"""

    def __init__(self):
        """Inicializa o gerenciador de salvamento"""
        self.base_dir = Path("relatorios_intermediarios")
        self.base_dir.mkdir(exist_ok=True)

        # Subdiret√≥rios para organiza√ß√£o
        self.subdirs = {
            'pesquisa_web': self.base_dir / 'pesquisa_web',
            'drivers_mentais': self.base_dir / 'drivers_mentais',
            'provas_visuais': self.base_dir / 'provas_visuais',
            'anti_objecao': self.base_dir / 'anti_objecao',
            'pre_pitch': self.base_dir / 'pre_pitch',
            'avatar': self.base_dir / 'avatar',
            'analise_completa': self.base_dir / 'analise_completa',
            'erros': self.base_dir / 'erros',
            'logs': self.base_dir / 'logs'
        }

        # Cria todos os subdiret√≥rios
        for subdir in self.subdirs.values():
            subdir.mkdir(exist_ok=True)

        self.session_id = None
        self.analysis_id = None
        self.current_session_id = None # Adicionado para uso interno

        logger.info(f"‚úÖ Auto Save Manager inicializado: {self.base_dir}")

    def _clean_segment_name(self, segmento: str) -> str:
        """Limpa nome do segmento para usar como nome de pasta"""
        # Remove caracteres especiais e substitui espa√ßos por underscores
        clean_name = re.sub(r'[^\w\s-]', '', segmento.strip())
        clean_name = re.sub(r'[-\s]+', '_', clean_name)
        return clean_name.lower()

    def iniciar_sessao(self, session_id: Optional[str] = None, segmento: str = None) -> str:
        """Inicia uma nova sess√£o de salvamento com pasta por segmento"""

        if not session_id:
            timestamp = int(time.time() * 1000)
            random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=9))
            session_id = f"session_{timestamp}_{random_id}"

        self.current_session_id = session_id
        self.session_id = session_id # Define session_id para ser consistente com o resto do c√≥digo
        self.analysis_id = f"analysis_{int(time.time())}_{uuid.uuid4().hex[:8]}" # Mantido para compatibilidade

        # Cria pasta espec√≠fica por segmento se fornecido
        if segmento:
            segmento_clean = self._clean_segment_name(segmento)
            segmento_path = os.path.join(str(self.base_dir), "por_segmento", segmento_clean)
            os.makedirs(segmento_path, exist_ok=True)

            # Cria link simb√≥lico da sess√£o na pasta do segmento
            session_path = os.path.join(str(self.base_dir), session_id)
            segmento_session_path = os.path.join(segmento_path, session_id)

            try:
                if not os.path.exists(segmento_session_path):
                    os.symlink(session_path, segmento_session_path)
            except OSError as e:
                logger.warning(f"Could not create symlink for session {session_id} in segment {segmento_clean}: {e}. Falling back to copy.")
                # Fallback: copia em vez de link simb√≥lico se symlink falhar
                try:
                    shutil.copytree(session_path, segmento_session_path)
                except Exception as copy_e:
                    logger.error(f"Failed to copy session {session_id} to {segmento_session_path}: {copy_e}")


        # Salva metadados da sess√£o
        self.salvar_etapa("session_metadata", {
            "session_id": session_id,
            "segmento": segmento,
            "segmento_path": segmento_clean if segmento else None,
            "started_at": time.time(),
            "started_at_formatted": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "version": "ARQV30 Enhanced v2.0"
        }, categoria="logs") # Salva em logs para metadados da sess√£o

        logger.info(f"üöÄ Sess√£o iniciada: {session_id}" + (f" (Segmento: {segmento})" if segmento else ""))
        return session_id

    def salvar_etapa(
        self,
        nome_etapa: str,
        dados: Any,
        status: str = "sucesso",
        timestamp: Optional[float] = None,
        categoria: str = "geral"
    ) -> str:
        """Salva etapa imediatamente com timestamp √∫nico"""

        timestamp = timestamp or time.time()
        timestamp_str = datetime.fromtimestamp(timestamp).strftime("%Y%m%d_%H%M%S_%f")[:-3]

        # Determina diret√≥rio baseado na categoria
        if categoria in self.subdirs:
            save_dir = self.subdirs[categoria]
        else:
            save_dir = self.base_dir

        # Se h√° sess√£o ativa, cria subdiret√≥rio
        if self.current_session_id: # Usando current_session_id para consist√™ncia
            save_dir = save_dir / self.current_session_id
            save_dir.mkdir(exist_ok=True)

        # Nome do arquivo TXT para dados limpos
        filename = f"{nome_etapa}_{timestamp_str}.txt"
        filepath = save_dir / filename

        try:
            # Prepara dados para salvamento
            save_data = {
                "etapa": nome_etapa,
                "status": status,
                "dados": self._serialize_data_safely(dados),
                "timestamp": timestamp,
                "timestamp_iso": datetime.fromtimestamp(timestamp).isoformat(),
                "session_id": self.current_session_id,
                "analysis_id": self.analysis_id,
                "categoria": categoria,
                "tamanho_dados": len(str(dados)) if dados else 0
            }

            # Salva arquivo TXT limpo (sem dados brutos JSON)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(f"ETAPA: {nome_etapa}\n")
                f.write(f"STATUS: {status}\n")
                f.write(f"TIMESTAMP: {datetime.fromtimestamp(timestamp).strftime('%d/%m/%Y %H:%M:%S')}\n")
                f.write(f"SESS√ÉO: {self.current_session_id}\n")
                f.write(f"CATEGORIA: {categoria}\n")
                f.write(f"TAMANHO: {len(str(dados)) if dados else 0} caracteres\n")
                f.write("=" * 50 + "\n")

                # Escreve dados de forma leg√≠vel (n√£o JSON bruto)
                self._write_data_safely(f, dados)

            # Log de sucesso
            logger.info(f"üíæ Etapa '{nome_etapa}' salva: {filepath}")

            # Salva tamb√©m backup JSON para dados cr√≠ticos
            if categoria in ['analise_completa', 'pesquisa_web'] and len(str(dados)) > 1000:
                json_filepath = save_dir / f"{nome_etapa}_{timestamp_str}.json"
                with open(json_filepath, "w", encoding="utf-8") as f:
                    json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)

            return str(filepath)

        except Exception as e:
            # Salvamento de emerg√™ncia em caso de erro
            emergency_path = self.base_dir / f"EMERGENCY_{nome_etapa}_{timestamp_str}.txt"
            try:
                with open(emergency_path, "w", encoding="utf-8") as f:
                    f.write(f"ERRO AO SALVAR: {str(e)}\n")
                    f.write(f"DADOS: {str(dados)[:1000]}...\n")
                    f.write(f"STATUS: {status}\n")
                    f.write(f"TIMESTAMP: {timestamp}\n")

                logger.error(f"‚ùå Erro ao salvar '{nome_etapa}': {e}")
                logger.info(f"üÜò Backup de emerg√™ncia salvo: {emergency_path}")

            except Exception as emergency_error:
                logger.critical(f"üö® FALHA CR√çTICA no salvamento de emerg√™ncia: {emergency_error}")

            return str(emergency_path)
    
    def _serialize_data_safely(self, data):
        """Serializa dados de forma segura evitando refer√™ncias circulares"""
        try:
            # Detecta e remove refer√™ncias circulares
            seen = set()
            
            def remove_circular_refs(obj, path="root"):
                obj_id = id(obj)
                if obj_id in seen:
                    return f"[Circular reference at {path}]"
                
                if isinstance(obj, (str, int, float, bool, type(None))):
                    return obj
                
                seen.add(obj_id)
                
                try:
                    if isinstance(obj, dict):
                        result = {}
                        for key, value in list(obj.items())[:50]:  # Limita a 50 chaves
                            try:
                                result[str(key)] = remove_circular_refs(value, f"{path}.{key}")
                            except Exception as e:
                                result[str(key)] = f"[Erro na serializa√ß√£o: {str(e)}]"
                        return result
                    elif isinstance(obj, list):
                        return [remove_circular_refs(item, f"{path}[{i}]") for i, item in enumerate(obj[:20])]
                    else:
                        return str(obj)[:500]
                finally:
                    seen.discard(obj_id)
            
            return remove_circular_refs(data)
            
        except Exception as e:
            logger.error(f"Erro na serializa√ß√£o segura: {e}")
            return f"[Dados n√£o serializ√°veis: {type(data).__name__}]"
    
    def _serialize_item_safely(self, item):
        """Serializa um item individual de forma segura"""
        try:
            if isinstance(item, (str, int, float, bool, type(None))):
                return item
            elif isinstance(item, dict):
                # Para dicion√°rios aninhados, limita profundidade
                safe_dict = {}
                for k, v in list(item.items())[:20]:  # Limita a 20 chaves
                    if isinstance(v, (str, int, float, bool, type(None))):
                        safe_dict[str(k)] = v
                    else:
                        safe_dict[str(k)] = str(v)[:200]  # Converte para string limitada
                return safe_dict
            elif isinstance(item, list):
                return [str(subitem)[:100] for subitem in item[:10]]  # Limita a 10 itens
            else:
                return str(item)[:200]
        except:
            return "[Item n√£o serializ√°vel]"
    
    def _write_data_safely(self, file_handle, dados):
        """Escreve dados de forma segura no arquivo"""
        try:
            if isinstance(dados, dict):
                for key, value in list(dados.items())[:50]:  # Limita a 50 chaves
                    try:
                        file_handle.write(f"\n{str(key).upper()}:\n")
                        if isinstance(value, list):
                            for item in value[:10]:  # Limita a 10 itens
                                file_handle.write(f"‚Ä¢ {str(item)[:200]}\n")
                        elif isinstance(value, dict):
                            for subkey, subvalue in list(value.items())[:5]:  # Limita a 5 subitens
                                file_handle.write(f"  {str(subkey)}: {str(subvalue)[:100]}\n")
                        else:
                            file_handle.write(f"{str(value)[:500]}\n")
                    except Exception as e:
                        file_handle.write(f"  [Erro ao escrever {key}: {str(e)}]\n")
            elif isinstance(dados, list):
                for i, item in enumerate(dados[:20], 1):  # Limita a 20 itens
                    try:
                        file_handle.write(f"{i}. {str(item)[:200]}\n")
                    except Exception as e:
                        file_handle.write(f"{i}. [Erro ao escrever item: {str(e)}]\n")
            else:
                file_handle.write(f"DADOS: {str(dados)[:1000]}\n")
        except Exception as e:
            file_handle.write(f"[ERRO AO ESCREVER DADOS: {str(e)}]\n")

    def salvar_erro(self, etapa: str, erro: Exception, contexto: Dict[str, Any] = None) -> str:
        """Salva erro com contexto completo"""

        erro_data = {
            "etapa": etapa,
            "tipo_erro": type(erro).__name__,
            "mensagem_erro": str(erro),
            "contexto": contexto or {},
            "stack_trace": self._get_stack_trace(erro),
            "timestamp_erro": time.time()
        }

        return self.salvar_etapa(f"ERRO_{etapa}", erro_data, status="erro", categoria="erros")

    def salvar_progresso(self, etapa_atual: str, progresso: float, detalhes: str = "") -> str:
        """Salva progresso atual"""

        progresso_data = {
            "etapa_atual": etapa_atual,
            "progresso_percentual": progresso,
            "detalhes": detalhes,
            "timestamp_progresso": time.time()
        }

        return self.salvar_etapa("progresso", progresso_data, categoria="logs")

    def recuperar_etapa(self, nome_etapa: str, session_id: str = None) -> Optional[Dict[str, Any]]:
        """Recupera dados de uma etapa espec√≠fica"""

        session_id = session_id or self.current_session_id
        if not session_id:
            logger.error("‚ùå Nenhuma sess√£o ativa")
            return None

        # Busca em todos os subdiret√≥rios
        for categoria, subdir in self.subdirs.items():
            session_dir = subdir / session_id
            if session_dir.exists():
                # Busca arquivos que come√ßam com o nome da etapa
                for filepath in session_dir.glob(f"{nome_etapa}_*.json"):
                    try:
                        with open(filepath, "r", encoding="utf-8") as f:
                            data = json.load(f)

                        if data.get("status") == "sucesso":
                            logger.info(f"üìÇ Etapa '{nome_etapa}' recuperada: {filepath}")
                            return data

                    except Exception as e:
                        logger.error(f"‚ùå Erro ao recuperar {filepath}: {e}")
                        continue

        return None

    def listar_etapas_salvas(self, session_id: str = None) -> Dict[str, Any]:
        """Lista todas as etapas salvas de uma sess√£o"""

        session_id = session_id or self.current_session_id
        if not session_id:
            return {}

        etapas_encontradas = {}

        for categoria, subdir in self.subdirs.items():
            session_dir = subdir / session_id
            if session_dir.exists():
                for filepath in session_dir.glob("*.json"):
                    try:
                        with open(filepath, "r", encoding="utf-8") as f:
                            data = json.load(f)

                        etapa = data.get("etapa", "unknown")
                        if etapa not in etapas_encontradas:
                            etapas_encontradas[etapa] = []

                        etapas_encontradas[etapa].append({
                            "arquivo": str(filepath),
                            "status": data.get("status"),
                            "timestamp": data.get("timestamp"),
                            "categoria": categoria,
                            "tamanho": data.get("tamanho_dados", 0)
                        })

                    except Exception as e:
                        logger.error(f"‚ùå Erro ao ler {filepath}: {e}")
                        continue

        return etapas_encontradas

    def consolidar_sessao(self, session_id: str = None) -> str:
        """Consolida todas as etapas de uma sess√£o em um relat√≥rio final"""

        session_id = session_id or self.current_session_id
        etapas = self.listar_etapas_salvas(session_id)

        # Recupera dados de cada etapa
        relatorio_consolidado = {
            "session_id": session_id,
            "analysis_id": self.analysis_id,
            "consolidado_em": datetime.now().isoformat(),
            "etapas_processadas": {},
            "estatisticas": {
                "total_etapas": len(etapas),
                "etapas_sucesso": 0,
                "etapas_erro": 0,
                "etapas_fallback": 0
            }
        }

        for etapa_nome, arquivos in etapas.items():
            # Pega o arquivo mais recente de cada etapa
            arquivo_mais_recente = max(arquivos, key=lambda x: x["timestamp"])

            try:
                with open(arquivo_mais_recente["arquivo"], "r", encoding="utf-8") as f:
                    dados_etapa = json.load(f)

                relatorio_consolidado["etapas_processadas"][etapa_nome] = dados_etapa

                # Atualiza estat√≠sticas
                status = dados_etapa.get("status", "unknown")
                if status == "sucesso":
                    relatorio_consolidado["estatisticas"]["etapas_sucesso"] += 1
                elif status == "erro":
                    relatorio_consolidado["estatisticas"]["etapas_erro"] += 1
                elif "fallback" in status:
                    relatorio_consolidado["estatisticas"]["etapas_fallback"] += 1

            except Exception as e:
                logger.error(f"‚ùå Erro ao consolidar etapa {etapa_nome}: {e}")
                continue

        # Salva relat√≥rio consolidado
        timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        relatorio_path = self.subdirs["analise_completa"] / f"CONSOLIDADO_{session_id}_{timestamp_str}.json"

        with open(relatorio_path, "w", encoding="utf-8") as f:
            json.dump(relatorio_consolidado, f, ensure_ascii=False, indent=2, default=str)

        logger.info(f"üìã Relat√≥rio consolidado salvo: {relatorio_path}")
        return str(relatorio_path)

    def _salvar_backup_compactado(self, filepath: Path, data: Dict[str, Any]):
        """Salva backup compactado para dados grandes"""
        try:
            backup_path = filepath.with_suffix('.json.gz')
            with gzip.open(backup_path, 'wt', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)

            logger.info(f"üóúÔ∏è Backup compactado salvo: {backup_path}")

        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar backup compactado: {e}")

    def _get_stack_trace(self, erro: Exception) -> str:
        """Obt√©m stack trace do erro"""
        return traceback.format_exc()

    def limpar_sessoes_antigas(self, dias: int = 7):
        """Remove sess√µes mais antigas que X dias"""
        try:
            cutoff_time = time.time() - (dias * 24 * 60 * 60)
            removidas = 0

            for subdir in self.subdirs.values():
                if subdir.is_dir():
                    for item in subdir.iterdir():
                        if item.is_dir():
                            # Verifica se √© mais antiga que o cutoff
                            if item.stat().st_mtime < cutoff_time:
                                shutil.rmtree(item)
                                removidas += 1
                                logger.info(f"üóëÔ∏è Sess√£o antiga removida: {item}")

            # Tamb√©m limpa pastas de segmento antigas
            segmento_base_path = self.base_dir / "por_segmento"
            if segmento_base_path.is_dir():
                 for segmento_dir in segmento_base_path.iterdir():
                     if segmento_dir.is_dir():
                         if segmento_dir.stat().st_mtime < cutoff_time:
                            shutil.rmtree(segmento_dir)
                            removidas += 1
                            logger.info(f"üóëÔ∏è Pasta de segmento antiga removida: {segmento_dir}")


            logger.info(f"üßπ Limpeza conclu√≠da: {removidas} sess√µes/segmentos antigos removidos")

        except Exception as e:
            logger.error(f"‚ùå Erro na limpeza de sess√µes antigas: {e}")

    def listar_sessoes(self) -> List[str]:
        """Lista todas as sess√µes salvas"""
        try:
            session_path = os.path.join(str(self.base_dir), "logs") # Corre√ß√£o: base_dir em vez de base_path
            if not os.path.exists(session_path):
                return []

            sessoes = []
            for item in os.listdir(session_path):
                # Verifica se o item √© um diret√≥rio e come√ßa com 'session_'
                item_path = os.path.join(session_path, item)
                if os.path.isdir(item_path) and item.startswith('session_'):
                    sessoes.append(item)

            return sessoes

        except Exception as e:
            logger.error(f"Erro ao listar sess√µes: {e}")
            return []

    def _list_session_files(self, session_id: str, categoria: str = None) -> List[str]:
        """Lista arquivos de uma sess√£o espec√≠fica"""
        try:
            files = []
            
            # Se categoria espec√≠fica foi fornecida
            if categoria and categoria in self.subdirs:
                session_dir = self.subdirs[categoria] / session_id
                if session_dir.exists():
                    for file_path in session_dir.glob("*"):
                        if file_path.is_file():
                            files.append(str(file_path))
            else:
                # Busca em todos os subdiret√≥rios
                for subdir in self.subdirs.values():
                    session_dir = subdir / session_id
                    if session_dir.exists():
                        for file_path in session_dir.glob("*"):
                            if file_path.is_file():
                                files.append(str(file_path))
            
            return files
            
        except Exception as e:
            logger.error(f"Erro ao listar arquivos da sess√£o {session_id}: {e}")
            return []

    def _list_session_files(self, session_id: str, categoria: str = None) -> List[str]:
        """Lista arquivos de uma sess√£o espec√≠fica"""
        try:
            files = []
            
            # Se categoria espec√≠fica foi fornecida
            if categoria and categoria in self.subdirs:
                session_dir = self.subdirs[categoria] / session_id
                if session_dir.exists():
                    for file_path in session_dir.glob("*"):
                        if file_path.is_file():
                            files.append(str(file_path))
            else:
                # Busca em todos os subdiret√≥rios
                for subdir in self.subdirs.values():
                    session_dir = subdir / session_id
                    if session_dir.exists():
                        for file_path in session_dir.glob("*"):
                            if file_path.is_file():
                                files.append(str(file_path))
            
            return files
            
        except Exception as e:
            logger.error(f"Erro ao listar arquivos da sess√£o {session_id}: {e}")
            return []

    def obter_info_sessao(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Obt√©m informa√ß√µes de uma sess√£o espec√≠fica"""
        try:
            # A l√≥gica original de `obter_info_sessao` utilizava `self.base_path`, que n√£o estava definido.
            # Assumindo que `self.base_dir` √© o caminho correto.
            session_dir_path = self.base_dir / "logs" / session_id
            
            if not session_dir_path.exists():
                # Tenta encontrar em outras categorias se n√£o for encontrada em logs
                for subdir in self.subdirs.values():
                    if subdir != self.subdirs['logs']: # Evita verificar a pasta de logs novamente
                        potential_session_path = subdir / session_id
                        if potential_session_path.exists():
                            session_dir_path = potential_session_path
                            break
                else: # Se o loop terminar sem encontrar
                    logger.info(f"Sess√£o '{session_id}' n√£o encontrada em nenhum diret√≥rio.")
                    return None

            etapas = {}
            for arquivo in os.listdir(session_dir_path):
                if arquivo.endswith('.txt') or arquivo.endswith('.json'):
                    # Extrai o nome da etapa do nome do arquivo.
                    # Assume que o nome da etapa √© tudo antes do primeiro '_' seguido por um timestamp num√©rico.
                    parts = arquivo.split('_')
                    if len(parts) > 1 and parts[1].startswith('20') and parts[1][:4].isdigit(): # Verifica se a segunda parte parece um timestamp
                        etapa_nome = '_'.join(parts[:-1]) # Reconstroi o nome da etapa, caso contenha underscores
                        timestamp_str = parts[-1].replace('.txt', '').replace('.json', '')
                    else: # Caso o padr√£o n√£o seja encontrado, usa o nome do arquivo como etapa
                        etapa_nome = arquivo.replace('.txt', '').replace('.json', '')
                        timestamp_str = 'unknown'

                    arquivo_path = session_dir_path / arquivo

                    with open(arquivo_path, 'r', encoding='utf-8') as f:
                        if arquivo.endswith('.json'):
                            dados = json.load(f)
                        else:
                            dados = f.read()

                    etapas[etapa_nome] = {
                        'arquivo': arquivo,
                        'dados': dados,
                        'timestamp': timestamp_str
                    }

            return {
                'session_id': session_id,
                'etapas': etapas,
                'total_etapas': len(etapas)
            }

        except Exception as e:
            logger.error(f"Erro ao obter info da sess√£o {session_id}: {e}")
            return None


# Inst√¢ncia global
auto_save_manager = AutoSaveManager()

# Fun√ß√£o de conveni√™ncia
def salvar_etapa(nome_etapa: str, dados: Any, status: str = "sucesso", categoria: str = "geral") -> str:
    """Fun√ß√£o de conveni√™ncia para salvamento r√°pido"""
    return auto_save_manager.salvar_etapa(nome_etapa, dados, status, categoria=categoria)

def salvar_erro(etapa: str, erro: Exception, contexto: Dict[str, Any] = None) -> str:
    """Fun√ß√£o de conveni√™ncia para salvamento de erros"""
    return auto_save_manager.salvar_erro(etapa, erro, contexto)